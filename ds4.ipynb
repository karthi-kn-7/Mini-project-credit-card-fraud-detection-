{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('train_transaction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of fraud cases in the dataset: 0.03499000914417313\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# List of columns to apply label encoding\n",
    "columns_to_encode = ['ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6',\n",
    "                     'addr1', 'addr2', 'P_emaildomain', 'R_emaildomain', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']\n",
    "\n",
    "# Apply label encoding for each column\n",
    "for column in columns_to_encode:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column].astype(str))\n",
    "\n",
    "# Calculate the number of missing values per column\n",
    "missing_values_per_column = df.isnull().sum()\n",
    "\n",
    "# Calculate the median of missing values\n",
    "median_missing_values = missing_values_per_column.median()\n",
    "\n",
    "# Exclude columns with missing values surpassing the median\n",
    "columns_to_exclude = missing_values_per_column[missing_values_per_column > median_missing_values].index\n",
    "df_cleaned = df.drop(columns=columns_to_exclude)\n",
    "\n",
    "# Impute missing values using median of respective columns\n",
    "df_cleaned.fillna(df_cleaned.median(), inplace=True)\n",
    "\n",
    "fraud_proportion = df['isFraud'].mean()\n",
    "\n",
    "print(\"Proportion of fraud cases in the dataset:\", fraud_proportion)\n",
    "\n",
    "# Now df_cleaned contains the preprocessed dataset with label encoded categorical columns and missing values imputed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         TransactionID  isFraud  TransactionDT  TransactionAmt  ProductCD  \\\n",
       "0             2987000        0          86400           68.50          4   \n",
       "1             2987001        0          86401           29.00          4   \n",
       "2             2987002        0          86469           59.00          4   \n",
       "3             2987003        0          86499           50.00          4   \n",
       "4             2987004        0          86506           50.00          1   \n",
       "...               ...      ...            ...             ...        ...   \n",
       "590535        3577535        0       15811047           49.00          4   \n",
       "590536        3577536        0       15811049           39.50          4   \n",
       "590537        3577537        0       15811079           30.95          4   \n",
       "590538        3577538        0       15811088          117.00          4   \n",
       "590539        3577539        0       15811131          279.95          4   \n",
       "\n",
       "        card1  card2  card3  card4  card5  ...   V312        V313        V314  \\\n",
       "0        3417    500     42      1     38  ...    0.0    0.000000    0.000000   \n",
       "1        7922    303     42      2      2  ...    0.0    0.000000    0.000000   \n",
       "2        9383    389     42      4     58  ...    0.0    0.000000    0.000000   \n",
       "3        6991    466     42      2     14  ...  135.0    0.000000    0.000000   \n",
       "4        9262    413     42      2      2  ...    0.0    0.000000    0.000000   \n",
       "...       ...    ...    ...    ...    ...  ...    ...         ...         ...   \n",
       "590535  10855    500     42      4    108  ...    0.0   47.950001   47.950001   \n",
       "590536    390    124     42      2    106  ...    0.0    0.000000    0.000000   \n",
       "590537   1782    494     42      2    106  ...    0.0    0.000000    0.000000   \n",
       "590538  11847    380     42      2    106  ...  117.0  317.500000  669.500000   \n",
       "590539   4361     69     42      2      2  ...    0.0    0.000000    0.000000   \n",
       "\n",
       "              V315  V316    V317   V318        V319        V320        V321  \n",
       "0         0.000000   0.0   117.0    0.0    0.000000    0.000000    0.000000  \n",
       "1         0.000000   0.0     0.0    0.0    0.000000    0.000000    0.000000  \n",
       "2         0.000000   0.0     0.0    0.0    0.000000    0.000000    0.000000  \n",
       "3         0.000000  50.0  1404.0  790.0    0.000000    0.000000    0.000000  \n",
       "4         0.000000   0.0     0.0    0.0    0.000000    0.000000    0.000000  \n",
       "...            ...   ...     ...    ...         ...         ...         ...  \n",
       "590535   47.950001   0.0     0.0    0.0    0.000000    0.000000    0.000000  \n",
       "590536    0.000000   0.0     0.0    0.0    0.000000    0.000000    0.000000  \n",
       "590537    0.000000   0.0     0.0    0.0    0.000000    0.000000    0.000000  \n",
       "590538  317.500000   0.0  2234.0    0.0    0.000000    0.000000    0.000000  \n",
       "590539    0.000000   0.0     0.0    0.0  279.950012  279.950012  279.950012  \n",
       "\n",
       "[590540 rows x 211 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_cleaned.drop(columns=['isFraud'])\n",
    "y=df_cleaned['isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590540\n",
      "590540 590540\n"
     ]
    }
   ],
   "source": [
    "print(len(df_cleaned))\n",
    "print(len(x),len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote=SMOTE(sampling_strategy='minority')\n",
    "x_sm,y_sm=smote.fit_resample(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isFraud\n",
       "0    569877\n",
       "1     20663\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isFraud\n",
       "0    569877\n",
       "1    569877\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x_sm,y_sm,test_size=.2,stratify=y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0   0.951557  0.802773  0.870856    113975\n",
      "           1   0.829442  0.959132  0.889585    113976\n",
      "\n",
      "    accuracy                       0.880952    227951\n",
      "   macro avg   0.890500  0.880952  0.880220    227951\n",
      "weighted avg   0.890499  0.880952  0.880220    227951\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "knn = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski', metric_params=None, n_jobs=-1, n_neighbors=5, p=2, weights='uniform')\n",
    "knn.fit(xtrain,ytrain)\n",
    "ypre_knn=knn.predict(xtest)\n",
    "print(\"Knn report\\n\",classification_report(ytest,ypre_knn,digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84    113975\n",
      "           1       0.84      0.82      0.83    113976\n",
      "\n",
      "    accuracy                           0.83    227951\n",
      "   macro avg       0.83      0.83      0.83    227951\n",
      "weighted avg       0.83      0.83      0.83    227951\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None, priors=None, shrinkage=None, solver='svd', store_covariance=False, tol=0.0001)\n",
    "lda.fit(xtrain, ytrain)\n",
    "ypre_lda = lda.predict(xtest)\n",
    "print(\"lda report\\n\", classification_report(ytest, ypre_lda))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.1302631217265497\n",
      "Mean Absolute Error (MAE): 0.29476044818808395\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr=LinearRegression()\n",
    "lr.fit(xtrain,ytrain)\n",
    "ypre_lr=lr.predict(xtest)\n",
    "\n",
    "mse = mean_squared_error(ytest, ypre_lr)\n",
    "mae = mean_absolute_error(ytest, ypre_lr)\n",
    "\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvl=sum(ypre_lr)/len(ypre_lr)\n",
    "por=[0]*len(ytest)\n",
    "for i in range(0,len(ypre_lr)):\n",
    "    if(ypre_knn[i]==0 or ypre_lda[i]==0):\n",
    "        if(ypre_lr[i]<mvl):\n",
    "            por[i]=0\n",
    "    elif(ypre_knn[i]==1 or ypre_lda[i]==1):\n",
    "        if(ypre_lr[i]>mvl):\n",
    "            por[i]=1\n",
    "    else:\n",
    "        por[i]=ypre_knn[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=accuracy_score(ytest,por)\n",
    "pcc=precision_score(ytest,por)\n",
    "ff=f1_score(ytest,por)\n",
    "re=recall_score(ytest,por)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc :  0.8771578102311461\n",
      "pre :  0.9603152506799735\n",
      "f1  :  0.8649607932022261\n",
      "re  :  0.7868323155752088\n"
     ]
    }
   ],
   "source": [
    "print(\"acc : \",acc)\n",
    "print(\"pre : \",pcc)\n",
    "print(\"f1  : \",ff)\n",
    "print(\"re  : \",re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89    113975\n",
      "           1       0.96      0.79      0.86    113976\n",
      "\n",
      "    accuracy                           0.88    227951\n",
      "   macro avg       0.89      0.88      0.88    227951\n",
      "weighted avg       0.89      0.88      0.88    227951\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest,por))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98    113975\n",
      "           1       0.98      0.98      0.98    113976\n",
      "\n",
      "    accuracy                           0.98    227951\n",
      "   macro avg       0.98      0.98      0.98    227951\n",
      "weighted avg       0.98      0.98      0.98    227951\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(xtrain,ytrain)\n",
    "ydt=clf.predict(xtest)\n",
    "\n",
    "print(\"DT report\\n\", classification_report(ytest, ydt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82    113975\n",
      "           1       0.83      0.79      0.81    113976\n",
      "\n",
      "    accuracy                           0.81    227951\n",
      "   macro avg       0.81      0.81      0.81    227951\n",
      "weighted avg       0.81      0.81      0.81    227951\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(xtrain, ytrain)\n",
    "yrf=clf.predict(xtest)\n",
    "\n",
    "print(\"RT report\\n\", classification_report(ytest, yrf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ET report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    113975\n",
      "           1       1.00      0.99      0.99    113976\n",
      "\n",
      "    accuracy                           0.99    227951\n",
      "   macro avg       0.99      0.99      0.99    227951\n",
      "weighted avg       0.99      0.99      0.99    227951\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(xtrain, ytrain)\n",
    "yet=clf.predict(xtest)\n",
    "print(\"ET report\\n\", classification_report(ytest, yet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95    113975\n",
      "           1       0.96      0.94      0.95    113976\n",
      "\n",
      "    accuracy                           0.95    227951\n",
      "   macro avg       0.95      0.95      0.95    227951\n",
      "weighted avg       0.95      0.95      0.95    227951\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100, algorithm=\"SAMME\", random_state=0)\n",
    "clf.fit(xtrain, ytrain)\n",
    "yab=clf.predict(xtest)\n",
    "\n",
    "print(\"AB report\\n\", classification_report(ytest, yab))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
